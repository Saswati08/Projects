{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7PW_eUVec3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDTeXROgNH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQioBZnytmI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My Drive/DL_assignment/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOiKmZ_Jux5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFSaZEPu4aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd ..\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g9UuaQru7oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Wk1zheu_eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd DL_assignment/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyNmNe-1vC_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "train_data1 = loadmat('Vol_01_input.mat')\n",
        "train_data2 = loadmat('Vol_02_input.mat')\n",
        "train_data3 = loadmat('Vol_05_input.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa8yxS1T48Fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label1 = loadmat('Vol_01gt.mat')\n",
        "train_label2 = loadmat('Vol_02gt.mat')\n",
        "train_label3 = loadmat('Vol_05gt.mat')\n",
        "# for keys in train_label1:\n",
        "#   print(keys, train_label1[keys])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E5TdOXKy0Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_data1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d3-Jrf7zm2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_data = train_data1['ana']\n",
        "tr_data2 = train_data2['ana']\n",
        "tr_data3 = train_data3['ana']\n",
        "print(tr_data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLqtDCOK5doQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_gt = train_label1['gt']\n",
        "tr_gt2 = train_label2['gt']\n",
        "tr_gt3 = train_label3['gt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNW9O3X0Clc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []\n",
        "for i in range(tr_data.shape[2]):\n",
        "  train_data.append(tr_data[:,][:,][i])\n",
        "for i in range(tr_data.shape[2]):\n",
        "  train_data.append(tr_data2[:,][:,][i])\n",
        "for i in range(tr_data.shape[2]):\n",
        "  train_data.append(tr_data3[:,][:,][i])\n",
        "print(len(train_data))\n",
        "print(train_data[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba8u8biy3iRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gt = []\n",
        "for i in range(tr_gt.shape[2]):\n",
        "  train_gt.append(tr_gt[:,][:,][i])\n",
        "for i in range(tr_gt.shape[2]):\n",
        "  train_gt.append(tr_gt2[:,][:,][i])\n",
        "for i in range(tr_gt.shape[2]):\n",
        "  train_gt.append(tr_gt3[:,][:,][i])\n",
        "print(len(train_gt))\n",
        "print(train_gt[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1a-OwejBO7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(train_gt[0] == 1)\n",
        "def check(mat, st_i, st_j):\n",
        "  i = st_i\n",
        "  j = st_j\n",
        "  flag = 0\n",
        "  # print(i, j)\n",
        "  while(i < st_i + 32):\n",
        "    j = st_j\n",
        "    while(j < st_j + 32):\n",
        "      if mat[i][j] == 0:\n",
        "        return False\n",
        "      if mat[i][j] == 1:\n",
        "        flag = 1\n",
        "      j += 1\n",
        "    i += 1\n",
        "  # if flag == 1:\n",
        "  #   return True\n",
        "  # else:\n",
        "  return True\n",
        "\n",
        "def make_patch(mat, st_i, st_j):\n",
        "  patch = np.zeros((32, 32))\n",
        "  i = st_i\n",
        "  j = st_j\n",
        "  a = 0\n",
        "  b = 0\n",
        "  while(i < st_i + 32):\n",
        "    j = st_j\n",
        "    b = 0\n",
        "    while(j < st_j + 32):\n",
        "      patch[a][b] = mat[i][j]\n",
        "      j += 1\n",
        "      b += 1\n",
        "    i += 1\n",
        "    a += 1\n",
        "  return patch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "jump = 30\n",
        "new_train_data = []\n",
        "new_train_gt = []\n",
        "for k in range(len(train_gt)):\n",
        "  for i in range(tr_gt.shape[1] - 32):\n",
        "    flag = 0\n",
        "    for j in range(tr_gt.shape[2] - 32):\n",
        "      if i != 0 and train_gt[k][i - 1][j] == 1:\n",
        "        continue\n",
        "      if train_gt[k][i][j] == 1:\n",
        "        if check(train_gt[k], i, j) == True:\n",
        "          patch_data = make_patch(train_data[k], i, j)\n",
        "          patch_gt = make_patch(train_gt[k], i, j)\n",
        "          new_train_data.append(patch_data)\n",
        "          patch_gt = patch_gt - 1\n",
        "          new_train_gt.append(patch_gt)\n",
        "          j = j + jump\n",
        "          flag = 1\n",
        "    # if flag == 1:\n",
        "    #   i = i + jump\n",
        "          \n",
        "\n",
        "print(len(new_train_data), len(new_train_gt))\n",
        "print(new_train_data[12].shape, new_train_gt[12].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkHwoxvxPqO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(32):\n",
        "  for j in range(32):\n",
        "    print(new_train_gt[201][i][j], end = \" \")\n",
        "  print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD11Zt0S596r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(new_train_gt[103].astype('uint8'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IOyOGEY3CK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "\n",
        "tensor_x = torch.Tensor(new_train_data) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(new_train_gt)\n",
        "\n",
        "my_dataset = data.TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "my_dataloader = data.DataLoader(my_dataset) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wMsSAmxeYiOD",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        print(\"Hii\")\n",
        "        super(SegNet, self).__init__()\n",
        "        print(\"Hello\")\n",
        "        self.conv1_1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        \n",
        "        self.unpool5 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool4 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool3 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool2 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool1 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "\n",
        "        self.conv_5_1 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_5_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_5_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_4_1 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_4_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_4_3 = nn.Conv2d(512, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_3_1 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_3_2 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_3_3 = nn.Conv2d(256, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_2_1 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_2_2 = nn.Conv2d(128, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_1_1 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv_1_2 = nn.Conv2d(64, 1, kernel_size = 3, stride = 1, padding = 1)\n",
        "        \n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"Alright?\")\n",
        "        size_1 = x.size()\n",
        "        print(\"Here?\")\n",
        "        x = self.conv1_1(x)\n",
        "        print(\"Reached Here?\")\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs1 = self.pool1(x)\n",
        "        \n",
        "        size_2 = x.size()\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs2 = self.pool2(x)\n",
        "        \n",
        "        size_3 = x.size()\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs3 = self.pool3(x)\n",
        "        \n",
        "        size_4 = x.size()\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs4 = self.pool4(x)\n",
        "\n",
        "        size_5 = x.size()\n",
        "        x = self.conv5_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv5_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv5_3(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs5 = self.pool5(x)\n",
        "\n",
        "        \n",
        "        x = self.unpool5(x, idxs5, output_size = size_5)\n",
        "        x = self.conv_5_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_5_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_5_3(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool4(x, idxs4, output_size = size_4)\n",
        "        x = self.conv_4_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_4_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_4_3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool3(x, idxs3, output_size = size_3)\n",
        "        x = self.conv_3_1(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_3_2(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_3_3(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool2(x, idxs2, output_size = size_2)\n",
        "        x = self.conv_2_1(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_2_2(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        print(\"Hii\")\n",
        "        \n",
        "        x = self.unpool1(x, idxs1, output_size = size_1)\n",
        "        x = self.conv_1_1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv_1_2(x)\n",
        "        output = F.softmax(x, dim = 3)\n",
        "        return x, output\n",
        "\n",
        "def dice_loss(true, logits, eps=1e-7):\n",
        "    \"\"\"Computes the Sørensen–Dice loss.\n",
        "    Note that PyTorch optimizers minimize a loss. In this\n",
        "    case, we would like to maximize the dice loss so we\n",
        "    return the negated dice loss.\n",
        "    Args:\n",
        "        true: a tensor of shape [B, 1, H, W].\n",
        "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
        "            the raw output or logits of the model.\n",
        "        eps: added to the denominator for numerical stability.\n",
        "    Returns:\n",
        "        dice_loss: the Sørensen–Dice loss.\n",
        "    \"\"\"\n",
        "    num_classes = logits.shape[1]\n",
        "    print(num_classes)\n",
        "    if num_classes == 1:\n",
        "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
        "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
        "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
        "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
        "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
        "        pos_prob = torch.sigmoid(logits)\n",
        "        neg_prob = 1 - pos_prob\n",
        "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
        "    else:\n",
        "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
        "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "    true_1_hot = true_1_hot.type(logits.type())\n",
        "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
        "    intersection = torch.sum(probas * true_1_hot, dims)\n",
        "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
        "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
        "    # print(dice_loss, 1 - dice_loss)\n",
        "    return (dice_loss)\n",
        "\n",
        "# def confusion_matrix(output, label):\n",
        "#   output = np.array(output)\n",
        "#   label = np.array(label)\n",
        "#   for i in range(output):\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20pfwjyGEf4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 0.001\n",
        "epochs = 1\n",
        "model = SegNet()\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 0.005)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_i5MsMb-Eul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('true')\n",
        "else:\n",
        "  print('false')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_28g4myfFxx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "for i in range(epochs):\n",
        "        start_time = time.time()\n",
        "        mean_loss = 0\n",
        "        tot = 0\n",
        "        idx = 0\n",
        "        for img, label in my_dataloader:\n",
        "            if torch.cuda.is_available():\n",
        "              label = label.cuda()\n",
        "              img = img.cuda()\n",
        "            img_r = torch.unsqueeze(img, 1)\n",
        "            img = img.type(torch.FloatTensor)\n",
        "            label_r = torch.unsqueeze(label, 1)\n",
        "            label = label.type(torch.LongTensor)\n",
        "            label = label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output, output_s = model(img_r)\n",
        "            # print(output.shape, label.shape)\n",
        "            loss = criterion(output, label)\n",
        "            loss2 = dice_loss(label, output)\n",
        "            # print(loss2.item())\n",
        "            tot += loss2.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            mean_loss += loss\n",
        "            idx += 1\n",
        "\n",
        "        print(idx)  \n",
        "        mean_loss /= idx\n",
        "        tot /= idx\n",
        "        end_time = time.time()\n",
        "        elapse_time = end_time - start_time\n",
        "        print(f'epoch {i} loss: {mean_loss}, elapse time: {elapse_time}', tot)\n",
        "        # if mean_loss < min_loss:\n",
        "        #     print(f'in epoch {i}, loss decline')\n",
        "        #     min_loss = mean_loss\n",
        "        #     state_dict = model.module.state_dict()\n",
        "        #     for key in state_dict.keys():\n",
        "        #         state_dict[key] = state_dict[key].cpu()\n",
        "        #         torch.save(state_dict, 'segnet_weight_11classes.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRQQyUcKQPjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78VuxjzbQuQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1 = output.argmax()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRxyBOjiRHlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = output.detach().cpu()\n",
        "x = np.array(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYCYKKYwRLWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK4UuOx-RXEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[0][2][i][j]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljD7CPezRZNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1 = x1.detach().cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy5-4q-IRpVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1 = np.array(x1)\n",
        "print(x1.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFM0pzr6RqnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9-RXl7nfmSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install torchsummary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EiCAR-QRzjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model,(1,1,32,32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zHcAAJkfgYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}