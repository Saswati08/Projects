{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalQ2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7PW_eUVec3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhDTeXROgNH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQioBZnytmI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd ..\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOiKmZ_Jux5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJFSaZEPu4aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g9UuaQru7oY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd My Drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Wk1zheu_eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd dl sas Q3/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyNmNe-1vC_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.io import loadmat\n",
        "train_data1 = loadmat('Vol_01_input.mat')\n",
        "train_data2 = loadmat('Vol_02_input.mat')\n",
        "train_data3 = loadmat('Vol_05_input.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGWBsIdh4OBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = loadmat('Vol_06_input.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa8yxS1T48Fx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label1 = loadmat('Vol_01gt.mat')\n",
        "train_label2 = loadmat('Vol_02gt.mat')\n",
        "train_label3 = loadmat('Vol_05gt.mat')\n",
        "# for keys in train_label1:\n",
        "#   print(keys, train_label1[keys])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJZf1n6C45sR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_gt = loadmat('Vol_06gt.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E5TdOXKy0Tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_data1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d3-Jrf7zm2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_data = train_data1['ana']\n",
        "tr_data2 = train_data2['ana']\n",
        "tr_data3 = train_data3['ana']\n",
        "print(tr_data.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7mpSfdA5JMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vl_data = val_data['ana']\n",
        "vl_gt = val_gt['gt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLqtDCOK5doQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_gt = train_label1['gt']\n",
        "tr_gt2 = train_label2['gt']\n",
        "tr_gt3 = train_label3['gt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNW9O3X0Clc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []\n",
        "for i in range(tr_data.shape[2]):\n",
        "  train_data.append(tr_data[:,][:,][i])\n",
        "for i in range(tr_data.shape[2]):\n",
        "  train_data.append(tr_data2[:,][:,][i])\n",
        "for i in range(tr_data.shape[2]):\n",
        "  train_data.append(tr_data3[:,][:,][i])\n",
        "print(len(train_data))\n",
        "print(train_data[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b1sClxp82Qa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_data = []\n",
        "for i in range(vl_data.shape[2]):\n",
        "  val_data.append(vl_data[:,][:,][i])\n",
        "val_gt = []\n",
        "for i in range(vl_gt.shape[2]):\n",
        "  val_gt.append(vl_gt[:,][:,][i])\n",
        "print(len(val_data), val_data[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9hf4DfIVynu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]]\n",
        "a = np.array(a)\n",
        "np.save('a.npy',a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cP-0bfbU4dn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.load('a.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba8u8biy3iRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gt = []\n",
        "for i in range(tr_gt.shape[2]):\n",
        "  train_gt.append(tr_gt[:,][:,][i])\n",
        "for i in range(tr_gt.shape[2]):\n",
        "  train_gt.append(tr_gt2[:,][:,][i])\n",
        "for i in range(tr_gt.shape[2]):\n",
        "  train_gt.append(tr_gt3[:,][:,][i])\n",
        "print(len(train_gt))\n",
        "print(train_gt[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDnCm2zF-gV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check(mat, st_i, st_j):\n",
        "  i = st_i\n",
        "  j = st_j\n",
        "  flag = 0\n",
        "  # print(i, j)\n",
        "  while(i < st_i + 32):\n",
        "    j = st_j\n",
        "    while(j < st_j + 32):\n",
        "      if mat[i][j] == 0:\n",
        "        return False\n",
        "      # if mat[i][j] == 1:\n",
        "      #   flag = 1\n",
        "      j += 1\n",
        "    i += 1\n",
        "  # if flag == 1:\n",
        "  #   return True\n",
        "  # else:\n",
        "  #   return False\n",
        "  return True\n",
        "\n",
        "def make_patch(mat, st_i, st_j):\n",
        "  patch = np.zeros((32, 32))\n",
        "  i = st_i - 16\n",
        "  j = st_j - 16\n",
        "  a = 0\n",
        "  b = 0\n",
        "  if i < 0:\n",
        "    i = st_i\n",
        "    st_i = 16\n",
        "  if j < 0:\n",
        "    j = st_j\n",
        "    st_j = 16\n",
        "    \n",
        "  while(i < st_i + 16):\n",
        "    j = st_j - 16\n",
        "    b = 0\n",
        "    while(j < st_j  + 16):\n",
        "      patch[a][b] = mat[i][j]\n",
        "      j += 1\n",
        "      b += 1\n",
        "    i += 1\n",
        "    a += 1\n",
        "  return patch\n",
        "\n",
        "\n",
        "jump = 8\n",
        "new_train_data = []\n",
        "new_train_gt = []\n",
        "for k in range(len(train_gt)):\n",
        "  for i in range(tr_gt.shape[1] - 32):\n",
        "    flag = 0\n",
        "    for j in range(tr_gt.shape[2] - 32):\n",
        "      \n",
        "      if train_gt[k][i][j] == 1:\n",
        "        allowed = check(train_gt[k], i, j)\n",
        "        if allowed == True:\n",
        "          patch_data = make_patch(train_data[k], i, j)\n",
        "          patch_gt = make_patch(train_gt[k], i, j)\n",
        "          new_train_data.append(patch_data)\n",
        "          patch_gt = patch_gt - 1\n",
        "          new_train_gt.append(patch_gt)\n",
        "          j = j + jump\n",
        "          i = i + jump\n",
        "          # flag = 1\n",
        "        # elif allowed == False and index >= 0:\n",
        "        #   j = index\n",
        "    if flag == 1:\n",
        "      i = i + jump\n",
        "print(len(new_train_data), len(new_train_gt))\n",
        "print(new_train_data[12].shape, new_train_gt[12].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt3iL3oVQJN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('new_train_data_v6.npy', new_train_data)\n",
        "np.save('new_train_gt_v6.npy', new_train_gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1a-OwejBO7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(train_gt[0] == 1)\n",
        "# def check(mat, st_i, st_j):\n",
        "#   i = st_i\n",
        "#   j = st_j\n",
        "#   flag = 0\n",
        "#   # print(i, j)\n",
        "#   while(i < st_i + 32):\n",
        "#     j = st_j\n",
        "#     while(j < st_j + 32):\n",
        "#       if mat[i][j] == 0:\n",
        "#         return False\n",
        "#       if mat[i][j] == 1:\n",
        "#         flag = 1\n",
        "#       j += 1\n",
        "#     i += 1\n",
        "#   # if flag == 1:\n",
        "#   #   return True\n",
        "#   # else:\n",
        "#   return True\n",
        "\n",
        "# def make_patch(mat, st_i, st_j):\n",
        "#   patch = np.zeros((32, 32))\n",
        "#   i = st_i\n",
        "#   j = st_j\n",
        "#   a = 0\n",
        "#   b = 0\n",
        "#   while(i < st_i + 32):\n",
        "#     j = st_j\n",
        "#     b = 0\n",
        "#     while(j < st_j + 32):\n",
        "#       patch[a][b] = mat[i][j]\n",
        "#       j += 1\n",
        "#       b += 1\n",
        "#     i += 1\n",
        "#     a += 1\n",
        "#   return patch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# jump = 30\n",
        "# new_train_data = []\n",
        "# new_train_gt = []\n",
        "# for k in range(len(train_gt)):\n",
        "#   for i in range(tr_gt.shape[1] - 32):\n",
        "#     flag = 0\n",
        "#     for j in range(tr_gt.shape[2] - 32):\n",
        "#       if i != 0 and train_gt[k][i - 1][j] == 1 and train_gt[k][i - 30][j] != 1:\n",
        "#         continue\n",
        "#       if train_gt[k][i][j] == 1:\n",
        "#         if check(train_gt[k], i, j) == True:\n",
        "#           patch_data = make_patch(train_data[k], i, j)\n",
        "#           patch_gt = make_patch(train_gt[k], i, j)\n",
        "#           new_train_data.append(patch_data)\n",
        "#           patch_gt = patch_gt - 1\n",
        "#           new_train_gt.append(patch_gt)\n",
        "#           j = j + jump\n",
        "#           # i = i + 2\n",
        "#           flag = 1\n",
        "#     # if flag == 1:\n",
        "#     #   i = i + jump\n",
        "          \n",
        "\n",
        "# print(len(new_train_data), len(new_train_gt))\n",
        "# print(new_train_data[12].shape, new_train_gt[12].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCKJq35yVQ9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.save('new_train_data.npy', new_train_data)\n",
        "# np.save('new_train_gt.npy', new_train_gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgLk5S2dQGmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY-kEGP2S2JC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_non_zero(mat):\n",
        "  i = 0\n",
        "  j = 0\n",
        "  while(i < 32):\n",
        "    j = 0\n",
        "    while(j < 32):\n",
        "      if mat[i][j] != 0:\n",
        "        return True\n",
        "      j += 1\n",
        "    i += 1  \n",
        "  return False\n",
        "\n",
        "\n",
        "\n",
        "new_val_data = []\n",
        "new_val_gt = []\n",
        "patch_data = np.zeros((32, 32))\n",
        "patch_gt = np.zeros((32, 32))\n",
        "for k in range(len(val_data)):\n",
        "  for i in range(128//32):\n",
        "    for j in range(256//32):\n",
        "      y = i * 32\n",
        "      z = j * 32\n",
        "      patch_data = make_patch(val_data[k], y, z)\n",
        "      if check_non_zero(patch_data) == True:\n",
        "        new_val_data.append(patch_data)\n",
        "        \n",
        "        patch_gt = make_patch(val_gt[k], y, z)\n",
        "        new_val_gt.append(patch_gt)\n",
        "print(len(new_val_data))\n",
        "print(new_val_data[120].shape)\n",
        "print(len(new_val_gt))\n",
        "print(new_val_gt[120].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFmxxOuRVmIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('new_val_data_v6.npy', new_val_data)\n",
        "np.save('new_val_gt_v6.npy', new_val_gt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkHwoxvxPqO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(32):\n",
        "  for j in range(32):\n",
        "    print(new_train_gt[990][i][j], end = \" \")\n",
        "  print()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD11Zt0S596r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(tr_gt2[:,][:,][80].astype('uint8'))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-XNjpt-ZP51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train_data = np.load('new_train_data_v4.npy')\n",
        "new_train_gt = np.load('new_train_gt_v4.npy')\n",
        "new_val_data = np.load('new_val_data_v4.npy')\n",
        "new_val_gt = np.load('new_val_gt_v4.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMxmPJEkWu8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_train_data[1000].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IOyOGEY3CK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "\n",
        "tensor_x = torch.Tensor(new_train_data) # transform to torch tensor\n",
        "tensor_y = torch.Tensor(new_train_gt)\n",
        "\n",
        "my_dataset = data.TensorDataset(tensor_x,tensor_y) # create your datset\n",
        "my_dataloader = data.DataLoader(my_dataset)\n",
        "\n",
        "\n",
        "tensor_vx = torch.Tensor(new_val_data)\n",
        "tensor_vy = torch.Tensor(new_val_gt)\n",
        "\n",
        "my_val = data.TensorDataset(tensor_vx,tensor_vy) # create your datset\n",
        "my_valoader = data.DataLoader(my_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwuctYv-EU-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        \n",
        "        self.conv1_1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0, return_indices = True)\n",
        "        \n",
        "        self.unpool5 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool4 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool3 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool2 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.unpool1 = nn.MaxUnpool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "\n",
        "        self.deconv5_1 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv5_2 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv5_3 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv4_1 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv4_2 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv4_3 = nn.ConvTranspose2d(512, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv3_1 = nn.ConvTranspose2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv3_2 = nn.ConvTranspose2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv3_3 = nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv2_1 = nn.ConvTranspose2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv2_2 = nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv1_1 = nn.ConvTranspose2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
        "        self.deconv1_2 = nn.ConvTranspose2d(64, 3, kernel_size = 3, stride = 1, padding = 1)\n",
        "\n",
        "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
        "        self.batch_norm4 = nn.BatchNorm2d(512)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        size_1 = x.size()\n",
        "        x = self.conv1_1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv1_2(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs1 = self.pool1(x)\n",
        "        \n",
        "        size_2 = x.size()\n",
        "        x = self.conv2_1(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2_2(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs2 = self.pool2(x)\n",
        "        \n",
        "        size_3 = x.size()\n",
        "        x = self.conv3_1(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3_2(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3_3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs3 = self.pool3(x)\n",
        "        \n",
        "        size_4 = x.size()\n",
        "        x = self.conv4_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4_3(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs4 = self.pool4(x)\n",
        "\n",
        "        size_5 = x.size()\n",
        "        x = self.conv5_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv5_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv5_3(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x, idxs5 = self.pool5(x)\n",
        "\n",
        "        \n",
        "        x = self.unpool5(x, idxs5, output_size = size_5)\n",
        "        x = self.deconv5_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv5_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv5_3(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool4(x, idxs4, output_size = size_4)\n",
        "        x = self.deconv4_1(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv4_2(x)\n",
        "        x = self.batch_norm4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv4_3(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool3(x, idxs3, output_size = size_3)\n",
        "        x = self.deconv3_1(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv3_2(x)\n",
        "        x = self.batch_norm3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv3_3(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool2(x, idxs2, output_size = size_2)\n",
        "        x = self.deconv2_1(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv2_2(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.unpool1(x, idxs1, output_size = size_1)\n",
        "        x = self.deconv1_1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.deconv1_2(x)\n",
        "        output = F.softmax(x, dim = 1)\n",
        "        return x, output\n",
        "\n",
        "def dice_loss(true, logits, eps=1e-7):\n",
        "    \"\"\"Computes the Sørensen–Dice loss.\n",
        "    Note that PyTorch optimizers minimize a loss. In this\n",
        "    case, we would like to maximize the dice loss so we\n",
        "    return the negated dice loss.\n",
        "    Args:\n",
        "        true: a tensor of shape [B, 1, H, W].\n",
        "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
        "            the raw output or logits of the model.\n",
        "        eps: added to the denominator for numerical stability.\n",
        "    Returns:\n",
        "        dice_loss: the Sørensen–Dice loss.\n",
        "    \"\"\"\n",
        "    num_classes = logits.shape[1]\n",
        "    if num_classes == 1:\n",
        "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
        "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
        "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
        "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
        "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
        "        pos_prob = torch.sigmoid(logits)\n",
        "        neg_prob = 1 - pos_prob\n",
        "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
        "    else:\n",
        "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
        "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "    true_1_hot = true_1_hot.type(logits.type())\n",
        "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
        "    intersection = torch.sum(probas * true_1_hot, dims)\n",
        "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
        "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
        "    # print(dice_loss, 1 - dice_loss)\n",
        "    return (dice_loss)\n",
        "\n",
        "def cal_confusion_matrix(output, label, val):\n",
        "  # if val == False:\n",
        "  output = output.cpu().detach()\n",
        "  output = np.array(output)\n",
        "  label = label.cpu().detach()\n",
        "  label = np.array(label)\n",
        "  confu_mat = np.zeros((3, 3))\n",
        "  pred_gt_equal = 0\n",
        "  tot_pix = 0\n",
        "  # print(output.shape)\n",
        "  # print(label.shape)\n",
        "  for i in range(output.shape[2]):\n",
        "    for j in range(output.shape[3]):\n",
        "      if val == True and label[0][i][j] == 0:\n",
        "        continue\n",
        "      tot_pix += 1\n",
        "      if output[0][0][i][j] > output[0][1][i][j] and output[0][0][i][j] > output[0][2][i][j]:\n",
        "        pred = 0\n",
        "      if output[0][1][i][j] > output[0][0][i][j] and output[0][1][i][j] > output[0][2][i][j]:\n",
        "        pred = 1\n",
        "      if output[0][2][i][j] > output[0][1][i][j] and output[0][2][i][j] > output[0][0][i][j]:\n",
        "        pred = 2\n",
        "      \n",
        "      #Confusion Matrix\n",
        "      # print(label[])\n",
        "      if val == False:\n",
        "        confu_mat[label[0][i][j]][pred] += 1 \n",
        "        if pred == label[0][i][j]:\n",
        "          pred_gt_equal += 1\n",
        "      else:\n",
        "        confu_mat[label[0][i][j] - 1][pred] += 1 \n",
        "        if pred == label[0][i][j] - 1:\n",
        "          pred_gt_equal += 1\n",
        "  return confu_mat\n",
        "\n",
        "\n",
        "def cal_dice_coefficient(output, label, val):\n",
        "  output = output.cpu().detach()\n",
        "  output = np.array(output)\n",
        "  label = label.cpu().detach()\n",
        "  label = np.array(label)\n",
        "  confu_mat = np.zeros((3, 3))\n",
        "  pred_gt_equal = 0\n",
        "  tot_pix = 0\n",
        "  # print(output.shape)\n",
        "  # print(label.shape)\n",
        "  for i in range(output.shape[2]):\n",
        "    for j in range(output.shape[3]):\n",
        "      if val == True and label[0][i][j] == 0:\n",
        "        continue\n",
        "      # print('here')\n",
        "      tot_pix += 1\n",
        "      if output[0][0][i][j] > output[0][1][i][j] and output[0][0][i][j] > output[0][2][i][j]:\n",
        "        pred = 0\n",
        "      if output[0][1][i][j] > output[0][0][i][j] and output[0][1][i][j] > output[0][2][i][j]:\n",
        "        pred = 1\n",
        "      if output[0][2][i][j] > output[0][1][i][j] and output[0][2][i][j] > output[0][0][i][j]:\n",
        "        pred = 2\n",
        "      if val == False:\n",
        "        if pred == label[0][i][j]:\n",
        "          pred_gt_equal += 1\n",
        "      else:\n",
        "        \n",
        "        if pred == label[0][i][j] - 1:\n",
        "          pred_gt_equal += 1\n",
        "  if tot_pix == 0:\n",
        "    return -1\n",
        "  dice_coefficient = pred_gt_equal/ (2 * tot_pix)\n",
        "  return dice_coefficient  \n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20pfwjyGEf4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "learning_rate = 0.0001\n",
        "epochs = 10\n",
        "model = SegNet()\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 0.005)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_i5MsMb-Eul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  print('true')\n",
        "else:\n",
        "  print('false')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_28g4myfFxx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "min_loss = 1\n",
        "for i in range(epochs):\n",
        "        start_time = time.time()\n",
        "        mean_loss = 0\n",
        "        tot = 0\n",
        "        idx = 0\n",
        "        confusion_matrix = np.zeros((3, 3))\n",
        "        dice_coefficient = 0\n",
        "        for img, label in my_dataloader:\n",
        "            \n",
        "            img_r = torch.unsqueeze(img, 1)\n",
        "            # print(img_r.shape)\n",
        "            if torch.cuda.is_available():\n",
        "              img_r = img_r.cuda()\n",
        "            # label_r = torch.unsqueeze(label, 1)\n",
        "            label = label.type(torch.LongTensor)\n",
        "            if torch.cuda.is_available():\n",
        "              label = label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            # print(img_r.shape)\n",
        "            output, output_s = model(img_r)\n",
        "            # print(output.shape, label.shape)\n",
        "            loss = criterion(output, label)\n",
        "            # loss2 = dice_loss(label, output)\n",
        "            # print(loss2.item())\n",
        "            confusion_matrix += cal_confusion_matrix(output_s, label, False)\n",
        "            dice_coefficient += cal_dice_coefficient(output_s, label, False)\n",
        "            # tot += loss2.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            mean_loss += loss\n",
        "            idx += 1\n",
        "\n",
        "        print(idx)  \n",
        "        mean_loss /= idx\n",
        "        tot /= idx\n",
        "        dice_coefficient /= idx\n",
        "        end_time = time.time()\n",
        "        elapse_time = end_time - start_time\n",
        "        print(f'epoch {i} loss: {mean_loss}, elapse time: {elapse_time}',  dice_coefficient)\n",
        "        for i in range(confusion_matrix.shape[0]):\n",
        "          for j in range(confusion_matrix.shape[1]):\n",
        "            print(confusion_matrix[i][j], end = \" \")\n",
        "          print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if mean_loss < min_loss:\n",
        "            print(f'in epoch {i}, loss decline')\n",
        "            torch.save(model, 'segnet_model_baseline_v2')\n",
        "            min_loss = mean_loss\n",
        "            # state_dict = model.module.state_dict()\n",
        "            # for key in state_dict.keys():\n",
        "            #     state_dict[key] = state_dict[key].cpu()\n",
        "            #     torch.save(state_dict, 'segnet_weight_baseline.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLRV0iy1qrlv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_s[0][2][1][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhbdETLctB94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "# model = torch.load('segnet_model_baseline_v2')\n",
        "# model.eval()\n",
        "mean_loss_v = 0\n",
        "tot_v = 0\n",
        "idx = 0\n",
        "tot_correct = 0\n",
        "tot_pixel = 0\n",
        "dice_coefficient = 0\n",
        "confusion_matrix_v = np.zeros((3, 3))\n",
        "with torch.no_grad():\n",
        "  for img_v, label_v in my_valoader:\n",
        "      \n",
        "      img_r = torch.unsqueeze(img_v, 1)\n",
        "      if torch.cuda.is_available():\n",
        "        img_r = img_r.cuda()\n",
        "      # img = img_v.type(torch.FloatTensor)\n",
        "      # label_r = torch.unsqueeze(label_v, 1)\n",
        "      label_v = label_v.type(torch.LongTensor)\n",
        "      if torch.cuda.is_available():\n",
        "        label_v = label_v.cuda()\n",
        "      output, output_s = model(img_r)\n",
        "      # print(output.shape, label.shape)\n",
        "      # loss = criterion(output_s, label_v)\n",
        "      # loss2 = dice_loss(label, output)\n",
        "      # print(loss2.item())\n",
        "      # print(type(output))\n",
        "      confusion_matrix_v += cal_confusion_matrix(output_s, label_v, True)\n",
        "      print(cal_confusion_matrix(output_s, label_v, True))\n",
        "      if cal_dice_coefficient(output_s, label_v, True) != -1:\n",
        "        dice_coefficient += cal_dice_coefficient(output_s, label_v, True)\n",
        "      else:\n",
        "        idx -= 1\n",
        "      # print(mat)\n",
        "      \n",
        "      # print(confusion_matrix_v)\n",
        "      \n",
        "      # tot_v += loss2.item()\n",
        "      \n",
        "      \n",
        "      # mean_loss_v += loss\n",
        "      idx += 1\n",
        "\n",
        "# print(idx_v)  \n",
        "# mean_loss_v /= idx\n",
        "tot_v /= idx\n",
        "dice_coefficient /= idx\n",
        "end_time = time.time()\n",
        "# elapse_time = end_time - start_time\n",
        "# print(f'epoch {i} elapse time: {elapse_time}', dice_coefficient)\n",
        "print(dice_coefficient)\n",
        "print(confusion_matrix_v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NofUHG6YwJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5K4qHEbR-Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(model, input_size = (1, 32, 32), batch_size = 1, device = 'cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXfGcqtPMU4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p39y95Qbkms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK3JexdNbpsm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = torch.load(\"segnet_model_skip_connections_10.pth\")\n",
        "model1.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}