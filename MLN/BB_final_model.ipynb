{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BB_final_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHEUVN_2FFe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyb_Ow3_FLpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My Drive/mln_project"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO59zm1R3Lxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install node2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v35lJvCrFeiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import math\n",
        "from scipy import spatial\n",
        "import pickle\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "from node2vec import Node2Vec\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRO8g59eFkpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file2 = 'RegularSeasonCompactResults.csv'\n",
        "df = pd.read_csv(file2, delimiter = ',', header = None)\n",
        "df = np.array(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0zB3sZ5F-4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df[:5])\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhWG5tGRFwKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_graph = nx.DiGraph()\n",
        "for i in range(1, df.shape[0] - 2000):\n",
        "  if int(df[i][0]) >= 2015:\n",
        "    train_graph.add_edge(int(df[i][2]), int(df[i][4]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FakH6fyVF7OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_graph.number_of_nodes(), train_graph.number_of_edges())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A60YXmKLKRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "players_win_map = {}\n",
        "for i in train_graph.nodes():\n",
        "  players_win_map[i] = []\n",
        "print(len(players_win_map))\n",
        "print(players_win_map)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsplCVOMGJgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr = nx.pagerank(train_graph, alpha=0.85)\n",
        "print('min',pr[min(pr, key=pr.get)])\n",
        "print('max',pr[max(pr, key=pr.get)])\n",
        "print('mean',float(sum(pr.values())) / len(pr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8ELHt6xHCdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hits = nx.hits(train_graph, max_iter=100, tol=1e-08, nstart=None, normalized=True)\n",
        "print('min',hits[0][min(hits[0], key=hits[0].get)])\n",
        "print('max',hits[0][max(hits[0], key=hits[0].get)])\n",
        "print('mean',float(sum(hits[0].values())) / len(hits[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlPE258EHOkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "katz = nx.katz.katz_centrality(train_graph,alpha=0.005,beta=1)\n",
        "print('min',katz[min(katz, key=katz.get)])\n",
        "print('max',katz[max(katz, key=katz.get)])\n",
        "print('mean',float(sum(katz.values())) / len(katz))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5pM-OGu3T2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "node2vec = Node2Vec(train_graph, dimensions = 20, walk_length = 16, num_walks = 50)\n",
        "model = node2vec.fit(window=7, min_count=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1ogcFXyHnfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_shortest_path_length(a,b):\n",
        "    p=-1\n",
        "    try:\n",
        "        if train_graph.has_edge(a,b):\n",
        "            train_graph.remove_edge(a,b)\n",
        "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
        "            train_graph.add_edge(a,b)\n",
        "        else:\n",
        "            p= nx.shortest_path_length(train_graph,source=a,target=b)\n",
        "        return p\n",
        "    except:\n",
        "        return -1\n",
        "\n",
        "def calc_adar_in(a,b):\n",
        "    sum=0\n",
        "    try:\n",
        "        n=list(set(train_graph.successors(a)).intersection(set(train_graph.successors(b))))\n",
        "        if len(n)!=0:\n",
        "            for i in n:\n",
        "                sum=sum+(1/np.log10(len(list(train_graph.predecessors(i)))))\n",
        "            return sum\n",
        "        else:\n",
        "            return 0\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def jaccard_for_followees(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.successors(a))) == 0  | len(set(train_graph.successors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.successors(a)).intersection(set(train_graph.successors(b)))))/\\\n",
        "                                    (len(set(train_graph.successors(a)).union(set(train_graph.successors(b)))))\n",
        "    except:\n",
        "        return 0\n",
        "    return sim\n",
        "#for followers\n",
        "def jaccard_for_followers(a,b):\n",
        "    try:\n",
        "        if len(set(train_graph.predecessors(a))) == 0  | len(set(g.predecessors(b))) == 0:\n",
        "            return 0\n",
        "        sim = (len(set(train_graph.predecessors(a)).intersection(set(train_graph.predecessors(b)))))/\\\n",
        "                                 (len(set(train_graph.predecessors(a)).union(set(train_graph.predecessors(b)))))\n",
        "        return sim\n",
        "    except:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0As2R09OnRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "player_pair_history = {}\n",
        "train_data = []\n",
        "train_label = []\n",
        "\n",
        "\n",
        "for i in range(1, df.shape[0] - 2000):\n",
        "  if int(df[i][0]) < 2015:\n",
        "    continue\n",
        "  ind = random.randint(0, 10)\n",
        "  if ind < 5:\n",
        "    wh = int(df[i][2])\n",
        "    bl = int(df[i][4])\n",
        "  else:\n",
        "    wh = int(df[i][4])\n",
        "    bl = int(df[i][2])\n",
        "  features = []\n",
        "  # features_neg = []\n",
        "  wid = int(df[i][2])\n",
        "  lid = int(df[i][4])\n",
        "  # add pagerank for white and black\n",
        "  features.append(pr[wh] - pr[bl])\n",
        "  # features_neg.append(pr[lid] - pr[wid])\n",
        "  \n",
        "  # add katz for white and black\n",
        "  features.append(katz[wh] - katz[bl])\n",
        "  # features_neg.append(katz[lid] - katz[wid])\n",
        "  \n",
        "  # add hits for white and black\n",
        "  features.append(hits[0][wh] - hits[0][bl])\n",
        "  features.append(hits[1][wh] - hits[1][bl])\n",
        "\n",
        "  # features_neg.append(- hits[0][wid] + hits[0][lid])\n",
        "  # features_neg.append( - hits[1][wid] + hits[1][lid])  \n",
        "\n",
        "  #add shortest distance between white and black\n",
        "  features.append(compute_shortest_path_length(wh, bl))\n",
        "  # features_neg.append(compute_shortest_path_length(lid, wid))\n",
        "  \n",
        "  #add adamic adar between white and black\n",
        "  features.append(calc_adar_in(wh, bl))\n",
        "  # features_neg.append(calc_adar_in(lid, wid))\n",
        "\n",
        "  #jaccard coeff between white and black for players defeated\n",
        "  features.append(jaccard_for_followees(wh, bl))\n",
        "  features.append(jaccard_for_followers(wh, bl))\n",
        "\n",
        "  # features_neg.append(jaccard_for_followees(lid, wid))\n",
        "  # features_neg.append(jaccard_for_followers(lid, wid))\n",
        "  \n",
        "  # white and black similarity\n",
        "  v1 = model[str(wh)]\n",
        "  v2 = model[str(bl)]\n",
        "  features.append(spatial.distance.cosine(v1, v2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # non graph related features\n",
        " \n",
        "  #performance of white against black previously\n",
        "  wh_wins = 0\n",
        "  bl_wins = 0\n",
        "  \n",
        "  if (wh, bl) in player_pair_history:\n",
        "    wh_wins = player_pair_history[(wh, bl)]\n",
        "    if wh == wid:\n",
        "      player_pair_history[(wh, bl)] = wh_wins + 1\n",
        "  else:\n",
        "    if wh == wid:\n",
        "      player_pair_history[(wh, bl)] = 1\n",
        "\n",
        "  if (bl, wh) in player_pair_history:\n",
        "    bl_wins = player_pair_history[(bl, wh)]\n",
        "    if bl == wid:\n",
        "      player_pair_history[(bl, wh)] = bl_wins + 1\n",
        "  else:\n",
        "    if bl == wid:\n",
        "      player_pair_history[(bl, wh)] = 1\n",
        "  features.append(wh_wins - bl_wins)\n",
        "  \n",
        "  if (train_graph.out_degree(wh) + train_graph.in_degree(wh)) != 0:\n",
        "    per_win_wh = train_graph.out_degree(wh)/(train_graph.out_degree(wh) + train_graph.in_degree(wh))\n",
        "  else:\n",
        "    per_win_wh = 0\n",
        "  if (train_graph.out_degree(bl) + train_graph.in_degree(bl)) != 0:\n",
        "    per_win_bl = train_graph.out_degree(bl)/(train_graph.out_degree(bl) + train_graph.in_degree(bl))\n",
        "  else:\n",
        "      per_win_bl = 0\n",
        "  features.append(per_win_wh - per_win_bl)\n",
        "\n",
        "  #performance of white in last 10 games\n",
        "  if wh in players_win_map:\n",
        "    history = players_win_map[wh]\n",
        "    if len(history) == 0:\n",
        "      # features.append(0)\n",
        "      \n",
        "      x = 0\n",
        "    else:\n",
        "      \n",
        "      if len(history) < 10:\n",
        "        \n",
        "        perf = np.count_nonzero(history == 1)\n",
        "        perf = perf/len(history)\n",
        "      else:\n",
        "        perf = np.count_nonzero(history[-10:] == 1)\n",
        "        perf = perf/10\n",
        "      \n",
        "      # features.append(perf)\n",
        "      x = perf\n",
        "      if wid == wh:\n",
        "        history.append(1)\n",
        "      else:\n",
        "        history.append(0)\n",
        "      players_win_map[wh] = history\n",
        "  else:\n",
        "    # features.append(0)\n",
        "    x = 1\n",
        "    players_win_map[wh] = [1]\n",
        "  \n",
        "  \n",
        "  #performance of black in last 10 games\n",
        "  if bl in players_win_map:\n",
        "    history = players_win_map[bl]\n",
        "    if len(history) == 0:\n",
        "      # features.append(0)\n",
        "      # features_neg.append(0)\n",
        "      y = 0\n",
        "    else:\n",
        "      # history = np.array(history)\n",
        "      perf = np.count_nonzero(history == 1)\n",
        "      if len(history) < 10:\n",
        "        perf = np.count_nonzero(history == 1)\n",
        "        perf = perf/len(history)\n",
        "        \n",
        "      else:\n",
        "        perf = np.count_nonzero(history[-10:] == 1)\n",
        "        perf = perf/10\n",
        "      \n",
        "      # features.append(perf)\n",
        "      # features_neg.append(perf) \n",
        "      y = perf\n",
        "      if bl == lid:\n",
        "        history.append(0)\n",
        "      else:\n",
        "        history.append(1)\n",
        "      players_win_map[bl] = history\n",
        "  else:\n",
        "    # features.append(0)\n",
        "    # features_neg.append(0)\n",
        "    y = 0\n",
        "    players_win_map[bl] = [0]\n",
        "\n",
        "  # features_neg.append(x)\n",
        "  features.append(x - y)\n",
        "\n",
        "  train_data.append(features)\n",
        "  # train_data.append(features_neg)\n",
        "  if int(df[i][2]) == wh:\n",
        "    train_label.append(1)\n",
        "  else:\n",
        "    train_label.append(0)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZC1IF17xc-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(train_data[1]))\n",
        "print(len(train_label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsYariVSxvoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = []\n",
        "test_label = []\n",
        "\n",
        "\n",
        "for i in range(df.shape[0] - 2000, df.shape[0]):\n",
        "  if int(df[i][0]) < 2015:\n",
        "    continue\n",
        "  ind = random.randint(0, 10)\n",
        "  if ind < 5:\n",
        "    wh = int(df[i][2])\n",
        "    bl = int(df[i][4])\n",
        "  else:\n",
        "    wh = int(df[i][4])\n",
        "    bl = int(df[i][2])\n",
        "  features = []\n",
        "  # features_neg = []\n",
        "  wid = int(df[i][2])\n",
        "  lid = int(df[i][4])\n",
        "  # add pagerank for white and black\n",
        "  features.append(pr[wh] - pr[bl])\n",
        "  # features_neg.append(pr[lid] - pr[wid])\n",
        "  \n",
        "  # add katz for white and black\n",
        "  features.append(katz[wh] - katz[bl])\n",
        "  # features_neg.append(katz[lid] - katz[wid])\n",
        "  \n",
        "  # add hits for white and black\n",
        "  features.append(hits[0][wh] - hits[0][bl])\n",
        "  features.append(hits[1][wh] - hits[1][bl])\n",
        "\n",
        "  # features_neg.append(- hits[0][wid] + hits[0][lid])\n",
        "  # features_neg.append( - hits[1][wid] + hits[1][lid])  \n",
        "\n",
        "  #add shortest distance between white and black\n",
        "  features.append(compute_shortest_path_length(wh, bl))\n",
        "  # features_neg.append(compute_shortest_path_length(lid, wid))\n",
        "  \n",
        "  #add adamic adar between white and black\n",
        "  features.append(calc_adar_in(wh, bl))\n",
        "  # features_neg.append(calc_adar_in(lid, wid))\n",
        "\n",
        "  #jaccard coeff between white and black for players defeated\n",
        "  features.append(jaccard_for_followees(wh, bl))\n",
        "  features.append(jaccard_for_followers(wh, bl))\n",
        "\n",
        "  # features_neg.append(jaccard_for_followees(lid, wid))\n",
        "  # features_neg.append(jaccard_for_followers(lid, wid))\n",
        "  \n",
        "  # white and black similarity\n",
        "  v1 = model[str(wh)]\n",
        "  v2 = model[str(bl)]\n",
        "  features.append(spatial.distance.cosine(v1, v2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # non graph related features\n",
        "  #performance of white in last 10 games\n",
        "  if wh in players_win_map:\n",
        "    history = players_win_map[wh]\n",
        "    if len(history) == 0:\n",
        "      # features.append(0)\n",
        "      \n",
        "      x = 0\n",
        "    else:\n",
        "      \n",
        "      if len(history) < 10:\n",
        "        \n",
        "        perf = np.count_nonzero(history == 1)\n",
        "        perf = perf/len(history)\n",
        "      else:\n",
        "        perf = np.count_nonzero(history[-10:] == 1)\n",
        "        perf = perf/10\n",
        "      \n",
        "      # features.append(perf)\n",
        "      x = perf\n",
        "      if wid == wh:\n",
        "        history.append(1)\n",
        "      else:\n",
        "        history.append(0)\n",
        "      players_win_map[wh] = history\n",
        "  else:\n",
        "    # features.append(0)\n",
        "    x = 1\n",
        "    players_win_map[wh] = [1]\n",
        "  \n",
        "  \n",
        "  #performance of black in last 10 games\n",
        "  if bl in players_win_map:\n",
        "    history = players_win_map[bl]\n",
        "    if len(history) == 0:\n",
        "      # features.append(0)\n",
        "      # features_neg.append(0)\n",
        "      y = 0\n",
        "    else:\n",
        "      # history = np.array(history)\n",
        "      perf = np.count_nonzero(history == 1)\n",
        "      if len(history) < 10:\n",
        "        perf = np.count_nonzero(history == 1)\n",
        "        perf = perf/len(history)\n",
        "        \n",
        "      else:\n",
        "        perf = np.count_nonzero(history[-10:] == 1)\n",
        "        perf = perf/10\n",
        "      \n",
        "      # features.append(perf)\n",
        "      # features_neg.append(perf) \n",
        "      y = perf\n",
        "      if bl == lid:\n",
        "        history.append(0)\n",
        "      else:\n",
        "        history.append(1)\n",
        "      players_win_map[bl] = history\n",
        "  else:\n",
        "    # features.append(0)\n",
        "    # features_neg.append(0)\n",
        "    y = 0\n",
        "    players_win_map[bl] = [0]\n",
        "\n",
        "  # features_neg.append(x)\n",
        "  features.append(x - y)\n",
        "  # features_neg.append(y - x)\n",
        "\n",
        "  #performance of white against black previously\n",
        "  wh_wins = 0\n",
        "  bl_wins = 0\n",
        "  \n",
        "  if (wh, bl) in player_pair_history:\n",
        "    wh_wins = player_pair_history[(wh, bl)]\n",
        "    if wh == wid:\n",
        "      player_pair_history[(wh, bl)] = wh_wins + 1\n",
        "  else:\n",
        "    if wh == wid:\n",
        "      player_pair_history[(wh, bl)] = 1\n",
        "\n",
        "  if (bl, wh) in player_pair_history:\n",
        "    bl_wins = player_pair_history[(bl, wh)]\n",
        "    if bl == wid:\n",
        "      player_pair_history[(bl, wh)] = bl_wins + 1\n",
        "  else:\n",
        "    if bl == wid:\n",
        "      player_pair_history[(bl, wh)] = 1\n",
        "  features.append(wh_wins - bl_wins)\n",
        "\n",
        "  if (train_graph.out_degree(wh) + train_graph.in_degree(wh)) != 0:\n",
        "    per_win_wh = train_graph.out_degree(wh)/(train_graph.out_degree(wh) + train_graph.in_degree(wh))\n",
        "  else:\n",
        "    per_win_wh = 0\n",
        "  if (train_graph.out_degree(bl) + train_graph.in_degree(bl)) != 0:\n",
        "    per_win_bl = train_graph.out_degree(bl)/(train_graph.out_degree(bl) + train_graph.in_degree(bl))\n",
        "  else:\n",
        "      per_win_bl = 0\n",
        "  features.append(per_win_wh - per_win_bl)\n",
        "\n",
        "  #performance of white in last 10 games\n",
        "  if wh in players_win_map:\n",
        "    history = players_win_map[wh]\n",
        "    if len(history) == 0:\n",
        "      # features.append(0)\n",
        "      \n",
        "      x = 0\n",
        "    else:\n",
        "      \n",
        "      if len(history) < 10:\n",
        "        \n",
        "        perf = np.count_nonzero(history == 1)\n",
        "        perf = perf/len(history)\n",
        "      else:\n",
        "        perf = np.count_nonzero(history[-10:] == 1)\n",
        "        perf = perf/10\n",
        "      \n",
        "      # features.append(perf)\n",
        "      x = perf\n",
        "      if wid == wh:\n",
        "        history.append(1)\n",
        "      else:\n",
        "        history.append(0)\n",
        "      players_win_map[wh] = history\n",
        "  else:\n",
        "    # features.append(0)\n",
        "    x = 1\n",
        "    players_win_map[wh] = [1]\n",
        "  \n",
        "  \n",
        "  #performance of black in last 10 games\n",
        "  if bl in players_win_map:\n",
        "    history = players_win_map[bl]\n",
        "    if len(history) == 0:\n",
        "      # features.append(0)\n",
        "      # features_neg.append(0)\n",
        "      y = 0\n",
        "    else:\n",
        "      # history = np.array(history)\n",
        "      perf = np.count_nonzero(history == 1)\n",
        "      if len(history) < 10:\n",
        "        perf = np.count_nonzero(history == 1)\n",
        "        perf = perf/len(history)\n",
        "        \n",
        "      else:\n",
        "        perf = np.count_nonzero(history[-10:] == 1)\n",
        "        perf = perf/10\n",
        "      \n",
        "      # features.append(perf)\n",
        "      # features_neg.append(perf) \n",
        "      y = perf\n",
        "      if bl == lid:\n",
        "        history.append(0)\n",
        "      else:\n",
        "        history.append(1)\n",
        "      players_win_map[bl] = history\n",
        "  else:\n",
        "    # features.append(0)\n",
        "    # features_neg.append(0)\n",
        "    y = 0\n",
        "    players_win_map[bl] = [0]\n",
        "\n",
        "  # features_neg.append(x)\n",
        "  features.append(x - y)\n",
        "\n",
        "  test_data.append(features)\n",
        "  # test_data.append(features_neg)\n",
        "  if int(df[i][2]) == wh:\n",
        "    test_label.append(1)\n",
        "  else:\n",
        "    test_label.append(0)\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMK0RfNdy4wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(test_data))\n",
        "print(len(test_data[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIULnsZSy_1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler().fit(train_data)\n",
        "train_data = scaler.transform(train_data)\n",
        "test_data = scaler.transform(test_data)\n",
        "lr.fit(train_data, train_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzrEI7GbzIqn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = lr.predict_proba(test_data)\n",
        "from sklearn.metrics import accuracy_score\n",
        "test_pred = lr.predict(test_data)\n",
        "print(accuracy_score(test_pred, test_label))\n",
        "print(\"Precision = {}\".format(precision_score(test_label, test_pred, average='weighted')))\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cfm = confusion_matrix(test_label, test_pred)\n",
        "df_cm = pd.DataFrame(cfm, range(2), range(2))\n",
        "# plt.figure(figsize=(10,7))\n",
        "sns.set(font_scale = 0.8) # for label size\n",
        "sns.heatmap(df_cm, annot=True, fmt = \"d\") # font size\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print(roc_auc_score(test_label, predictions[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxKoFi4NKnvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_label = np.array(test_label)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr_1, tpr_1, _ = roc_curve(test_label, predictions[:,1])\n",
        "fpr_0, tpr_0, _ = roc_curve(1 - test_label, predictions[:, 0])\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr_0, tpr_0, color='red',\n",
        "         lw=lw, label='Win')\n",
        "plt.plot(fpr_1, tpr_1, color='blue',\n",
        "         lw=lw, label='Loss')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.savefig('roc_BB.png', dpi = 500)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPZ6m5JdzNCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth = 8, random_state=0)\n",
        "clf.fit(train_data, train_label)\n",
        "print(clf.score(train_data, train_label))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DU8jEWv1AQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_pred = clf.predict(test_data)\n",
        "predictions = clf.predict_proba(test_data)\n",
        "print(accuracy_score(test_pred, test_label))\n",
        "print(roc_auc_score(test_label, predictions[:, 1]))\n",
        "from sklearn.metrics import precision_score\n",
        "print(\"Precision = {}\".format(precision_score(test_label, test_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfUgxOvJ1Ivr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cfm = confusion_matrix(test_label, test_pred)\n",
        "df_cm = pd.DataFrame(cfm, range(2), range(2))\n",
        "# plt.figure(figsize=(10,7))\n",
        "sns.set(font_scale = 0.8) # for label size\n",
        "sns.heatmap(df_cm, annot=True, fmt = \"d\") # font size\n",
        "plt.savefig('cm_BB.png', dpi = 500)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-yPMxmx1gCp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = np.array(train_data)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "importances = clf.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "feature_name = [\"Page Rank Diff\", \"Katz Centrality Diff\", \"Hub Score Diff\", \"AUthority Score Diff\", \"Shortest Path\", \"Adamic Adar\", \"JC incoming\", \"JC outgoing\" , \"Node2vec similarity\",\"overall winning %\", \"% wins against opponent\", \"% wins in recent(10) games diff\"]\n",
        "for f in range(train_data.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" \" + feature_name[indices[f]])\n",
        "\n",
        "# Plot the impurity-based feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(train_data.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(train_data.shape[1]), indices)\n",
        "plt.xlim([-1, train_data.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-J8756M1pKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(random_state=1, max_iter=300).fit(train_data, train_label)\n",
        "print(clf.score(train_data, train_label))\n",
        "predictions = clf.predict_proba(test_data)\n",
        "print(roc_auc_score(test_label, predictions[:,1], average = \"macro\", multi_class='ovr'))\n",
        "print(accuracy_score(test_pred, test_label))\n",
        "print(\"Precision = {}\".format(precision_score(test_label, test_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCeYLeK23LEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "param = {\n",
        "    'eta': 0.3, \n",
        "    'max_depth': 3,  \n",
        "    'objective': 'multi:softprob',  \n",
        "    'num_class': 2} \n",
        "\n",
        "steps = 20 \n",
        "train_d = xgb.DMatrix(train_data, label = train_label)\n",
        "test_d = xgb.DMatrix(test_data, label= test_label)\n",
        "model = xgb.train(param, train_d, steps)\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "\n",
        "preds = model.predict(test_d)\n",
        "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
        "\n",
        "print(\"Precision = {}\".format(precision_score(test_label, best_preds, average='weighted')))\n",
        "print(\"Recall = {}\".format(recall_score(test_label, best_preds, average='macro')))\n",
        "print(\"Accuracy = {}\".format(accuracy_score(test_label, best_preds)))\n",
        "print(roc_auc_score(test_label, preds[:,1], average = \"macro\", multi_class='ovr'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVWWnCDM4hry",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cfm = confusion_matrix(test_label, best_preds)\n",
        "df_cm = pd.DataFrame(cfm, range(2), range(2))\n",
        "# plt.figure(figsize=(10,7))\n",
        "sns.set(font_scale = 0.8) # for label size\n",
        "sns.heatmap(df_cm, annot=True, fmt = \"d\") # font size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj22WNd5HVMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def degree_distribution(G):\n",
        "    degree_sequence = sorted([d for n, d in G.degree()], reverse=True)\n",
        "    #Degree of nodes in decreasing manner\n",
        "    # print (\"Degree sequence\", degree_sequence)\n",
        "    dmax = max(degree_sequence)\n",
        "    x, y = np.unique(degree_sequence, return_counts=True)\n",
        "    #counting the frequency of nodes having a particular degree \n",
        "    x = x[1:,]\n",
        "    y = y[1:,]\n",
        "    # print(x[0:100])\n",
        "\n",
        "    x = np.log10(x)\n",
        "    y = y/G.number_of_nodes()\n",
        "    y = np.log10(y)\n",
        "\n",
        "\n",
        "    # print(x.shape, y.shape)\n",
        "    x = x.reshape(-1, 1)\n",
        "    # print(x)\n",
        "    # print(y)\n",
        "#     model = LinearRegression()\n",
        "#     model.fit(x, y)\n",
        "#     m = model.coef_\n",
        "    # print(m)\n",
        "    # print(c)\n",
        "#     c = model.intercept_\n",
        "#     fx = m * x + c\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5c_c8KKe1iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x, y = degree_distribution(train_graph)\n",
        "\n",
        "\n",
        "plt1, = plt.plot(x, y, 'o', label = 'BasketBall Game')\n",
        "plt.legend(handles=[plt1])\n",
        "plt.title(\"Degree distribution in loglog scale\")\n",
        "plt.ylabel(\"Fraction of Nodes\")\n",
        "plt.xlabel(\"Degree\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6EtaWu0hFbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "degree_sequence = sorted([d for n, d in train_graph.out_degree()], reverse=True)\n",
        "# print \"Degree sequence\", degree_sequence\n",
        "dmax = max(degree_sequence)\n",
        "print(dmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g2KKgIhe_z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "degree_sequence = sorted([d for n, d in train_graph.in_degree()], reverse=True)\n",
        "# print \"Degree sequence\", degree_sequence\n",
        "dmax = max(degree_sequence)\n",
        "print(dmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaVA0OJDhKLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(nx.average_clustering(train_graph))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAyDGydEhUOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def plot_degree_dist(G):\n",
        "    degrees = [G.degree(n) for n in G.nodes()]\n",
        "    plt.hist(degrees)\n",
        "    plt.xlabel('Degree')\n",
        "    plt.ylabel('Number of Nodes')\n",
        "    plt.title('Degree Distribution')\n",
        "    plt.savefig('dd_BB.png', dpi = 500)\n",
        "    plt.show()\n",
        "\n",
        "plot_degree_dist(train_graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZyAYmcvUMJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}